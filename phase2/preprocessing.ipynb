{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas_datareader as pdr\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data for the two stocks chosen (best performing)\n",
    "zts = pd.read_excel('~/capp30254_fight_potatoes/data processing/data_processed_v2_0513.xlsx', sheet_name='ZTS')\n",
    "bio = pd.read_excel('~/capp30254_fight_potatoes/data processing/data_processed_v2_0513.xlsx', sheet_name='BIO')\n",
    "date = zts['Report Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/y6jssnk56235t8wjc47m1fdw0000gn/T/ipykernel_12282/2413775163.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(test_data)\n",
      "/var/folders/bq/y6jssnk56235t8wjc47m1fdw0000gn/T/ipykernel_12282/2413775163.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(test_data)\n"
     ]
    }
   ],
   "source": [
    "# get data for daily stock indicators\n",
    "tickers = ['ZTS','BIO']\n",
    "all_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for i in tickers:\n",
    "    test_data = pdr.get_data_yahoo(i, start = dt.datetime(2020,2,28), end = dt.date.today())\n",
    "    test_data['symbol'] = i\n",
    "    all_data = all_data.append(test_data)\n",
    "\n",
    "#Creating Return column\n",
    "all_data['return'] = all_data.groupby('symbol')['Close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSI\n",
    "all_data['Diff'] = all_data.groupby('symbol')['Close'].transform(lambda x: x.diff())\n",
    "all_data['Up'] = all_data['Diff']\n",
    "all_data.loc[(all_data['Up']<0), 'Up'] = 0\n",
    "\n",
    "all_data['Down'] = all_data['Diff']\n",
    "all_data.loc[(all_data['Down']>0), 'Down'] = 0 \n",
    "all_data['Down'] = abs(all_data['Down'])\n",
    "\n",
    "all_data['avg_5up'] = all_data.groupby('symbol')['Up'].transform(lambda x: x.rolling(window=5).mean())\n",
    "all_data['avg_5down'] = all_data.groupby('symbol')['Down'].transform(lambda x: x.rolling(window=5).mean())\n",
    "\n",
    "all_data['avg_15up'] = all_data.groupby('symbol')['Up'].transform(lambda x: x.rolling(window=15).mean())\n",
    "all_data['avg_15down'] = all_data.groupby('symbol')['Down'].transform(lambda x: x.rolling(window=15).mean())\n",
    "\n",
    "all_data['RS_5'] = all_data['avg_5up'] / all_data['avg_5down']\n",
    "all_data['RS_15'] = all_data['avg_15up'] / all_data['avg_15down']\n",
    "\n",
    "all_data['RSI_5'] = 100 - (100/(1+all_data['RS_5']))\n",
    "all_data['RSI_15'] = 100 - (100/(1+all_data['RS_15']))\n",
    "\n",
    "all_data['RSI_ratio'] = all_data['RSI_5']/all_data['RSI_15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACD\n",
    "all_data['5Ewm'] = all_data.groupby('symbol')['Close'].transform(lambda x: x.ewm(span=5, adjust=False).mean())\n",
    "all_data['15Ewm'] = all_data.groupby('symbol')['Close'].transform(lambda x: x.ewm(span=15, adjust=False).mean())\n",
    "all_data['MACD'] = all_data['15Ewm'] - all_data['5Ewm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only RSI and MACD\n",
    "all_data['Report Date'] = all_data.index\n",
    "all_data.reset_index(drop=True)\n",
    "all_data = all_data[['symbol', 'Report Date', 'RSI_ratio', 'MACD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge indicators and rest of data\n",
    "zts = zts.merge(all_data, how = 'left', left_on = ['Report Date' , 'Ticker'], right_on = ['Report Date', 'symbol'])\n",
    "bio = bio.merge(all_data, how = 'left', left_on = ['Report Date' , 'Ticker'], right_on = ['Report Date', 'symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ticker', 'Report Date', 'Stock price',\n",
       "       '(Dividends + Share Buyback) / FCF', 'Asset Turnover',\n",
       "       'CapEx / (Depr + Amor)', 'Current Ratio', 'Debt Ratio',\n",
       "       'Dividends / FCF', 'Dummy_Dividends', 'Gross Profit Margin',\n",
       "       'Interest Coverage', 'Inventory Turnover', 'Log Revenue',\n",
       "       'Net Profit Margin', 'Quick Ratio', 'R&D / Gross Profit',\n",
       "       'R&D / Revenue', 'Return on Assets', 'Return on Equity',\n",
       "       'Return on Research Capital', 'Share Buyback / FCF', 'tweet_polarity',\n",
       "       'tweet_subjectivity', 'p_diff', 's_diff', 'price_diff', 'symbol',\n",
       "       'RSI_ratio', 'MACD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative change for polarity/subjectivity\n",
    "# \n",
    "\n",
    "def processing(df, change = 0):\n",
    "    '''\n",
    "    Transforms absolute polarity and subjectivity\n",
    "    to relative terms.\n",
    "\n",
    "    Add a third label that represents no change in\n",
    "    the stock price. Y_dummy ∈ {-1, 0 ,1}\n",
    "\n",
    "    Inputs:\n",
    "        df: pandas df\n",
    "        change: threshold for pct change; ex: 0.025 means +/- 2.5%\n",
    "    \n",
    "    Returns:\n",
    "        X: df features\n",
    "        y_price: Stock prices\n",
    "        y_binary: Y_dummy ∈ {-1, 0 ,1}\n",
    "    '''\n",
    "    df['p_diff'] = df['tweet_polarity'].pct_change()\n",
    "    df['s_diff'] = df['tweet_subjectivity'].pct_change()\n",
    "    df['price_diff'] = df['Stock price'].pct_change()\n",
    "    condlist = [df['price_diff'] < -change, df['price_diff'] > change]\n",
    "    choices = [-1, 1]\n",
    "    y_binary = np.select(condlist, choices, 0)\n",
    "    y_price = df[['Stock price']]\n",
    "    X = df.iloc[:, 3: -2]\n",
    "    X.drop(['symbol'], axis=1, inplace=True)\n",
    "    return X, y_price, y_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example call to processing for zts with 2.5% point margin\n",
    "t, typ, tyb = processing(zts, 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature normalization\n",
    "def normalize(X_train, X_test):\n",
    "    '''\n",
    "    Normalize features using sklearn MinMaxScaler\n",
    "    '''\n",
    "    norm = MinMaxScaler().fit(X_train)\n",
    "    X_train_norm = norm.transform(X_train)\n",
    "    X_test_norm = norm.transform(X_test)\n",
    "    #scaler = MinMaxScaler()\n",
    "    #X_norm = scaler.fit_transform(X)\n",
    "    # make into pd df\n",
    "    X_train_norm = pd.DataFrame(X_train_norm, columns = X.columns)\n",
    "    X_test_norm = pd.DataFrame(X_test_norm, columns = X.columns)\n",
    "    return X_train_norm, X_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to select data given date window\n",
    "def window(start, end, df, date):\n",
    "    '''\n",
    "    Given a start and end date, return df with data only\n",
    "    from that period\n",
    "    \n",
    "    Inputs:\n",
    "        start/end: start and end dates\n",
    "            ex: start = '2022-01-23' ('YYYY-MM-DD')\n",
    "        df: pd dataframe\n",
    "        date: pd series with dates of all possible dates in data\n",
    "    \n",
    "    Returns: pd dataframe\n",
    "    '''\n",
    "    date = date[date.between(start, end, inclusive='both')]\n",
    "    # concat dates and dataframe\n",
    "    df = pd.concat([date, df], axis = 1, join=\"inner\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for training data 2021 Q4\n",
    "start = '2021-10-01'\n",
    "end = '2021-12-31'\n",
    "# stock price\n",
    "typ1 = window(start, end, typ, date)\n",
    "# training\n",
    "zts_norm1 = window(start, end, t, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data for different train/test windows\n",
    "zts = pd.read_csv('~/capp30254_fight_potatoes/data processing/zts_all_date_processed.csv')\n",
    "bio = pd.read_csv('~/capp30254_fight_potatoes/data processing/bio_all_date_processed.csv')\n",
    "# convert report date to pd datetime\n",
    "zts['Report Date'] = pd.to_datetime(zts['Report Date'])\n",
    "bio['Report Date'] = pd.to_datetime(bio['Report Date'])\n",
    "date = zts['Report Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data for different train/test windows\n",
    "all_windows = [[['2020-03-02', '2020-12-31'], ['2021-01-01', '2021-06-30']],[['2020-06-01', '2021-03-31'],['2021-04-01','2021-09-30']],\n",
    "      [['2020-09-01', '2021-06-30'],['2021-07-01','2021-12-31']], [['2021-01-01', '2021-09-30'],['2021-10-01','2022-04-24']], [['2021-03-01', '2021-12-31'],['2022-01-01','2022-04-24']]]\n",
    "stock = [zts, bio]\n",
    "stock_str = ['zts', 'bio']\n",
    "cols = list(zts.columns)\n",
    "cols.append('s_diff')\n",
    "\n",
    "for i, tic in enumerate(stock):\n",
    "    group = 0\n",
    "    for wd in all_windows:\n",
    "        train_wd, test_wd = wd\n",
    "        train_start, train_end = train_wd\n",
    "        test_start, test_end = test_wd\n",
    "        \n",
    "        # process (subjectivity pct change)\n",
    "        df = tic\n",
    "        df['s_diff'] = df['tweet_subjectivity'].pct_change()\n",
    "        X = df.iloc[:, 3:]\n",
    "        #t_norm = normalize(X)\n",
    "        # get Y_price\n",
    "        typ = df[['Stock price']]\n",
    "\n",
    "        # save training data\n",
    "        typ_train = window(train_start, train_end, typ, date)\n",
    "        \n",
    "        Y_dummy_train = pd.DataFrame(tic, columns = ['Y_boolean'])\n",
    "        tyb_train = window(train_start, train_end, Y_dummy_train, date)\n",
    "        X_train = window(train_start, train_end, X, date)\n",
    "        X_test = window(test_start, test_end, X, date)\n",
    "        # normalize data\n",
    "        X_train_norm, X_test_norm = normalize(X_train.iloc[:, 1:], X_test.iloc[:, 1:])\n",
    "        df_train = pd.merge(typ_train, tyb_train)\n",
    "        #df_train = pd.merge(df_train,X_train_norm)\n",
    "        df_train = pd.concat([df_train, X_train_norm], ignore_index=True, axis = 1)\n",
    "        df_train.columns = cols\n",
    "        df_train.to_csv(f'~/capp30254_fight_potatoes/data processing/window_data/{stock_str[i]}_train_group{group}_{train_start}_{train_end}.csv')\n",
    "        \n",
    "        # save testing data\n",
    "        typ_test = window(test_start, test_end, typ, date)\n",
    "        Y_dummy_test = pd.DataFrame(tic, columns = ['Y_boolean'])\n",
    "        tyb_test = window(test_start, test_end, Y_dummy_test, date)\n",
    "        #X_test = window(test_start, test_end, t_norm, date)\n",
    "        df_test = pd.merge(typ_test, tyb_test)\n",
    "        #df_test = pd.merge(df_test,X_train_norm)\n",
    "        df_test = pd.concat([df_test, X_test_norm], ignore_index=True, axis = 1)\n",
    "        df_test.columns = cols\n",
    "        df_test.to_csv(f'~/capp30254_fight_potatoes/data processing/window_data/{stock_str[i]}_test_group{group}_{test_start}_{test_end}.csv')\n",
    "        \n",
    "        group += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase 3\n",
    "# subset data for different train/test windows\n",
    "zts = pd.read_csv('~/capp30254_fight_potatoes/data processing/zts_all_date_processed.csv')\n",
    "bio = pd.read_csv('~/capp30254_fight_potatoes/data processing/bio_all_date_processed.csv')\n",
    "# convert report date to pd datetime\n",
    "zts['Report Date'] = pd.to_datetime(zts['Report Date'])\n",
    "bio['Report Date'] = pd.to_datetime(bio['Report Date'])\n",
    "date = zts['Report Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase 3 normalization\n",
    "\n",
    "def normalize(X):\n",
    "    '''\n",
    "    Normalize features using sklearn\n",
    "    '''\n",
    "    scaler = MinMaxScaler()\n",
    "    X_norm = scaler.fit_transform(X)\n",
    "    # make into pd df\n",
    "    X_norm = pd.DataFrame(X_norm, columns = X.columns)\n",
    "    return X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = [zts, bio]\n",
    "stock_str = ['zts', 'bio']\n",
    "cols = zts.columns\n",
    "for i, tic in enumerate(stock):\n",
    "    df = tic\n",
    "    df['s_diff'] = df['tweet_subjectivity'].pct_change()\n",
    "    Y = df.iloc[:, :3]\n",
    "    X = df.iloc[:, 3:]\n",
    "    X_norm = normalize(X)\n",
    "    # put back together\n",
    "    out = pd.concat([Y, X_norm], ignore_index=True, axis = 1)\n",
    "    out.columns = cols\n",
    "    out.to_csv(f'~/capp30254_fight_potatoes/data processing/{stock_str[i]}_norm.csv')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
